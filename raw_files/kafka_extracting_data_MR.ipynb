{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Movie Recommendations: Data Collection & Processing\n",
    "This notebook documents the process of collecting and processing movie data from Kafka.\n",
    "We extract movie watch events and ratings, clean the data, and prepare it for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connecting to Kafka & Extracting Data\n",
    "We first establish a connection to the Kafka broker and extract all past movie interaction data from `movielog2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NetID@cs594.cs.uic.edu) Password: Connection to localhost port 9092 [tcp/XmlIpcRegSvc] succeeded!\n"
     ]
    }
   ],
   "source": [
    "# Establish SSH connection to Kafka server (Run this in terminal, not in Jupyter)\n",
    "!ssh -o ServerAliveInterval=60 -L 9092:localhost:9092 NetID@cs594.cs.uic.edu -NTf # edit the NetId to your NetID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Kafka Connection\n",
    "!nc -zv localhost 9092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the Python Virtual Environment \n",
    "!source kafka_lab_env/bin/activate  # On macOS/Linux\n",
    "!kafka_lab_env/Scripts/activate  # On Windows\n",
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️. Listing Available Kafka Topics\n",
    "We check for available topics to find the one containing movie logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaAdminClient\n",
    "\n",
    "# Connect to Kafka Admin\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=\"localhost:9092\"\n",
    ")\n",
    "\n",
    "# Get all topics\n",
    "topics = admin_client.list_topics()\n",
    "print(\"Available Topics in Kafka VM:\")\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extracting Data from Kafka Topic 'movielog2'\n",
    "This section uses a Kafka consumer to read all past data from the topic and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import pandas as pd\n",
    "\n",
    "# Define Kafka Consumer\n",
    "consumer = KafkaConsumer(\n",
    "    'movielog2',  # Replace with your topic name\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',  # Read from the beginning\n",
    "    enable_auto_commit=False\n",
    ")\n",
    "\n",
    "# Initialize list to store messages\n",
    "data_list = []\n",
    "\n",
    "# Fetch and store messages\n",
    "for message in consumer:\n",
    "    data = message.value.decode('utf-8')  # Decode message from bytes to string\n",
    "    print(f\"Received: {data}\")  # Print each message\n",
    "    data_list.append([data])  # Append data as a list\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_list, columns=[\"Message\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"movielog2_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ All past data successfully saved to movielog2_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Processing & Cleaning Extracted Kafka Data\n",
    "We extract movie watch events and ratings from raw logs and structure them into a usable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read raw Kafka logs\n",
    "with open(\"movielog2_data.csv\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Movie Watch Data\n",
    "This extracts timestamps, user IDs, and movie names from logs where users watched movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_data = []\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split(\",\")\n",
    "\n",
    "    if len(parts) < 3:\n",
    "        continue\n",
    "\n",
    "    timestamp = parts[0]\n",
    "    user_id = parts[1]\n",
    "    match = re.search(r'GET /data/m/(.+)/\\d+\\.mpg', parts[2])\n",
    "\n",
    "    if match:\n",
    "        movie_name = match.group(1).replace(\"+\", \" \")\n",
    "        watch_data.append([timestamp, user_id, movie_name])\n",
    "\n",
    "# Convert to DataFrame\n",
    "watch_df = pd.DataFrame(watch_data, columns=[\"Timestamp\", \"User_ID\", \"Movie_Name\"])\n",
    "\n",
    "# Remove duplicate watches (keep only one entry per user per movie)\n",
    "watch_df = watch_df.drop_duplicates(subset=[\"User_ID\", \"Movie_Name\"])\n",
    "\n",
    "print(\"✅ Movie watch data extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Movie Rating Data\n",
    "This extracts timestamps, user IDs, and ratings from logs where users rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = []\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split(\",\")\n",
    "\n",
    "    if len(parts) < 3:\n",
    "        continue\n",
    "\n",
    "    timestamp = parts[0]\n",
    "    user_id = parts[1]\n",
    "    match = re.search(r'GET /rate/(.+)=(\\d+)', parts[2])\n",
    "\n",
    "    if match:\n",
    "        movie_name = match.group(1).replace(\"+\", \" \")\n",
    "        rating = match.group(2)\n",
    "        rating_data.append([timestamp, user_id, movie_name, rating])\n",
    "\n",
    "# Convert to DataFrame\n",
    "rating_df = pd.DataFrame(rating_data, columns=[\"Timestamp\", \"User_ID\", \"Movie_Name\", \"Rating\"])\n",
    "\n",
    "print(\"✅ Movie rating data extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merging Watch and Rating Data\n",
    "We merge both datasets based on User_ID and Movie_Name to get a structured final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge watch and rating data\n",
    "final_df = pd.merge(watch_df, rating_df, on=[\"User_ID\", \"Movie_Name\"], how=\"left\")\n",
    "\n",
    "# Save final merged file\n",
    "final_df.to_csv(\"final_processed_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final processed dataset saved as 'final_processed_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
